{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a998eb4f-150f-4be1-894f-826f7d8cd2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('omw-1.4')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b1fc2-20ef-4291-bf4a-5a5663bba51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "text = \"Hello Hem bhai, how are you?\"\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemma = lemmatizer.lemmatize(\"running\", pos=\"v\")\n",
    "print(\"Lemma:\", lemma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73026e20-ec3b-4f4f-876c-6d6f1c6e4608",
   "metadata": {},
   "source": [
    "## A) First, Dataset (Intents (Custom Dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c7e383-a198-4e16-a222-3728481f2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "   \"intents\":[\n",
    " {\n",
    "   \"tag\": \"greeting\",\n",
    "   \"patterns\": [\n",
    "      \"Hi\",\n",
    "      \"How are you?\",\n",
    "      \"Is anyone there?\",\n",
    "      \"Hello\",\n",
    "      \"Good day\",\n",
    "      \"What's up\",\n",
    "      \"how are ya\",\n",
    "      \"heyy\",\n",
    "      \"whatsup\",\n",
    "      \"??? ??? ??\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"Hello!\",\n",
    "      \"Good to see you again!\",\n",
    "      \"Hi there, how can I help?\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"goodbye\",\n",
    "   \"patterns\": [\n",
    "      \"cya\",\n",
    "      \"see you\",\n",
    "      \"bye bye\",\n",
    "      \"See you later\",\n",
    "      \"Goodbye\",\n",
    "      \"I am Leaving\",\n",
    "      \"Bye\",\n",
    "      \"Have a Good day\",\n",
    "      \"talk to you later\",\n",
    "      \"ttyl\",\n",
    "      \"i got to go\",\n",
    "      \"gtg\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"Sad to see you go :(\",\n",
    "      \"Talk to you later\",\n",
    "      \"Goodbye!\",\n",
    "      \"Come back soon\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"creator\",\n",
    "   \"patterns\": [\n",
    "      \"what is the name of your developers\",\n",
    "      \"what is the name of your creators\",\n",
    "      \"what is the name of the developers\",\n",
    "      \"what is the name of the creators\",\n",
    "      \"who created you\",\n",
    "      \"your developers\",\n",
    "      \"your creators\",\n",
    "      \"who are your developers\",\n",
    "      \"developers\",\n",
    "      \"you are made by\",\n",
    "      \"you are made by whom\",\n",
    "      \"who created you\",\n",
    "      \"who create you\",\n",
    "      \"creators\",\n",
    "      \"who made you\",\n",
    "      \"who designed you\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"Hem Prakash Dev from IIT Jodhpur\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"name\",\n",
    "   \"patterns\": [\n",
    "      \"name\",\n",
    "      \"your name\",\n",
    "      \"do you have a name\",\n",
    "      \"what are you called\",\n",
    "      \"what is your name\",\n",
    "      \"what should I call you\",\n",
    "      \"whats your name?\",\n",
    "      \"what are you\",\n",
    "      \"who are you\",\n",
    "      \"who is this\",\n",
    "      \"what am i chatting to\",\n",
    "      \"who am i taking to\",\n",
    "      \"what are you\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"You can call me Hem's IIT Jodhpur Enquire Chatbox.\",\n",
    "      \"I'm Hem's IIT Jodhpur Enquire Chatbox\",\n",
    "      \"I am a Hem's IIT Jodhpur Enquire Chatbox.\",\n",
    "      \"I am your helper\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"hours\",\n",
    "   \"patterns\": [\n",
    "      \"timing of college\",\n",
    "      \"what is college timing\",\n",
    "      \"working days\",\n",
    "      \"when are you guys open\",\n",
    "      \"what are your hours\",\n",
    "      \"hours of operation\",\n",
    "      \"when is the college open\",\n",
    "      \"college timing\",\n",
    "      \"what about college timing\",\n",
    "      \"is college open on saturday\",\n",
    "      \"tell something about college timing\",\n",
    "      \"what is the college  hours\",\n",
    "      \"when should i come to college\",\n",
    "      \"when should i attend college\",\n",
    "      \"what is my college time\",\n",
    "      \"college timing\",\n",
    "      \"timing college\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"IIT Jodhpur is open 8am-5pm Monday-Saturday!\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"number\",\n",
    "   \"patterns\": [\n",
    "      \"more info\",\n",
    "      \"contact info\",\n",
    "      \"how to contact college\",\n",
    "      \"college telephone number\",\n",
    "      \"college number\",\n",
    "      \"What is your contact no\",\n",
    "      \"Contact number?\",\n",
    "      \"how to call you\",\n",
    "      \"College phone no?\",\n",
    "      \"how can i contact you\",\n",
    "      \"Can i get your phone number\",\n",
    "      \"how can i call you\",\n",
    "      \"phone number\",\n",
    "      \"phone no\",\n",
    "      \"call\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"You can contact at: 7984864096\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"course\",\n",
    "   \"patterns\": [\n",
    "      \"list of courses\",\n",
    "      \"list of courses offered\",\n",
    "      \"list of courses offered in\",\n",
    "      \"what are the courses offered in your college?\",\n",
    "      \"courses?\",\n",
    "      \"courses offered\",\n",
    "      \"courses offered in (your univrsity(UNI) name)\",\n",
    "      \"courses you offer\",\n",
    "      \"branches?\",\n",
    "      \"courses available at UNI?\",\n",
    "      \"branches available at your college?\",\n",
    "      \"what are the courses in UNI?\",\n",
    "      \"what are branches in UNI?\",\n",
    "      \"what are courses in UNI?\",\n",
    "      \"branches available in UNI?\",\n",
    "      \"can you tell me the courses available in UNI?\",\n",
    "      \"can you tell me the branches available in UNI?\",\n",
    "      \"computer engineering?\",\n",
    "      \"computer\",\n",
    "      \"Computer engineering?\",\n",
    "      \"it\",\n",
    "      \"IT\",\n",
    "      \"Information Technology\",\n",
    "      \"AI/Ml\",\n",
    "      \"Mechanical engineering\",\n",
    "      \"Chemical engineering\",\n",
    "      \"Civil engineering\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"IIT Jodhpur offers Information Technology, computer Engineering, Mechanical engineering,Chemical engineering, Civil engineering and extc Engineering.\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"fees\",\n",
    "   \"patterns\": [\n",
    "      \"information about fee\",\n",
    "      \"information on fee\",\n",
    "      \"tell me the fee\",\n",
    "      \"college fee\",\n",
    "      \"fee per semester\",\n",
    "      \"what is the fee of each semester\",\n",
    "      \"what is the fees of each year\",\n",
    "      \"what is fee\",\n",
    "      \"what is the fees\",\n",
    "      \"how much is the fees\",\n",
    "      \"fees for first year\",\n",
    "      \"fees\",\n",
    "      \"about the fees\",\n",
    "      \"tell me something about the fees\",\n",
    "      \"What is the fees of hostel\",\n",
    "      \"how much is the fees\",\n",
    "      \"hostel fees\",\n",
    "      \"fees for AC room\",\n",
    "      \"fees for non-AC room\",\n",
    "      \"fees for Ac room for girls\",\n",
    "      \"fees for non-Ac room for girls\",\n",
    "      \"fees for Ac room for boys\",\n",
    "      \"fees for non-Ac room for boys\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"For Fee detail visit For Fee detail visit iitj.ac.in \"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"location\",\n",
    "   \"patterns\": [\n",
    "      \"where is the college located\",\n",
    "      \"college is located at\",\n",
    "      \"where is college\",\n",
    "      \"where is college located\",\n",
    "      \"address of college\",\n",
    "      \"how to reach college\",\n",
    "      \"college location\",\n",
    "      \"college address\",\n",
    "      \"wheres the college\",\n",
    "      \"how can I reach college\",\n",
    "      \"whats is the college address\",\n",
    "      \"what is the address of college\",\n",
    "      \"address\",\n",
    "      \"location\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"for location please visit https://maps.app.goo.gl/fqng76QgDKwa8S3u9\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"hostel\",\n",
    "   \"patterns\": [\n",
    "      \"hostel facility\",\n",
    "      \"hostel servive\",\n",
    "      \"hostel location\",\n",
    "      \"hostel address\",\n",
    "      \"hostel facilities\",\n",
    "      \"hostel fees\",\n",
    "      \"Does college provide hostel\",\n",
    "      \"Is there any hostel\",\n",
    "      \"Where is hostel\",\n",
    "      \"do you have hostel\",\n",
    "      \"do you guys have hostel\",\n",
    "      \"hostel\",\n",
    "      \"hostel capacity\",\n",
    "      \"what is the hostel fee\",\n",
    "      \"how to get in hostel\",\n",
    "      \"what is the hostel address\",\n",
    "      \"how far is hostel from college\",\n",
    "      \"hostel college distance\",\n",
    "      \"where is the hostel\",\n",
    "      \"how big is the hostel\",\n",
    "      \"distance between college and hostel\",\n",
    "      \"distance between hostel and college\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"For hostel detail at IIT Jodhpur visit https://iitj.ac.in/admission/phd.php?id=hostel_facilioties\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"event\",\n",
    "   \"patterns\": [\n",
    "      \"events organised\",\n",
    "      \"list of events\",\n",
    "      \"list of events organised in college\",\n",
    "      \"list of events conducted in college\",\n",
    "      \"What events are conducted in college\",\n",
    "      \"Are there any event held at college\",\n",
    "      \"Events?\",\n",
    "      \"functions\",\n",
    "      \"what are the events\",\n",
    "      \"tell me about events\",\n",
    "      \"what about events\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"For event detail at IIT Jodhpur visit https://alumni.iitj.ac.in/events?cat=all&search=%7B%7D\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"document\",\n",
    "   \"patterns\": [\n",
    "      \"document to bring\",\n",
    "      \"documents needed for admision\",\n",
    "      \"documents needed at the time of admission\",\n",
    "      \"documents needed during admission\",\n",
    "      \"documents required for admision\",\n",
    "      \"documents required at the time of admission\",\n",
    "      \"documents required during admission\",\n",
    "      \"What document are required for admission\",\n",
    "      \"Which document to bring for admission\",\n",
    "      \"documents\",\n",
    "      \"what documents do i need\",\n",
    "      \"what documents do I need for admission\",\n",
    "      \"documents needed\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"To know more about document required for admission at IIT Jodhpur visit https://iitj.ac.in/admission/mtech.php?id=registration_academic_session\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"floors\",\n",
    "   \"patterns\": [\n",
    "      \"size of campus\",\n",
    "      \"building size\",\n",
    "      \"How many floors does college have\",\n",
    "      \"floors in college\",\n",
    "      \"floors in college\",\n",
    "      \"how tall is UNI's College of Engineering college building\",\n",
    "      \"floors\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"IIT Jodhpur has total 4 floors Building \"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"syllabus\",\n",
    "   \"patterns\": [\n",
    "      \"Syllabus for IT\",\n",
    "      \"what is the Information Technology syllabus\",\n",
    "      \"syllabus\",\n",
    "      \"timetable\",\n",
    "      \"what is IT syllabus\",\n",
    "      \"syllabus\",\n",
    "      \"What is next lecture\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"Timetable provide direct to the students OR To know about syllabus visit http://academics.iitj.ac.in/?page_id=57 \"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"library\",\n",
    "   \"patterns\": [\n",
    "      \"is there any library\",\n",
    "      \"library facility\",\n",
    "      \"library facilities\",\n",
    "      \"do you have library\",\n",
    "      \"does the college have library facility\",\n",
    "      \"college library\",\n",
    "      \"where can i get books\",\n",
    "      \"book facility\",\n",
    "      \"Where is library\",\n",
    "      \"Library\",\n",
    "      \"Library information\",\n",
    "      \"Library books information\",\n",
    "      \"Tell me about library\",\n",
    "      \"how many libraries\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"There is one huge and spacious library.timings are 8am to 6pm and for more visit https://library.iitj.ac.in \"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"infrastructure\",\n",
    "   \"patterns\": [\n",
    "      \"how is college infrastructure\",\n",
    "      \"infrastructure\",\n",
    "      \"college infrastructure\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"IIt Jodhpur  has Excellent Infrastructure. Campus is clean. Good IT Labs With Good Speed of Internet connection\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"canteen\",\n",
    "   \"patterns\": [\n",
    "      \"food facilities\",\n",
    "      \"canteen facilities\",\n",
    "      \"canteen facility\",\n",
    "      \"is there any canteen\",\n",
    "      \"Is there a cafetaria in college\",\n",
    "      \"Does college have canteen\",\n",
    "      \"Where is canteen\",\n",
    "      \"where is cafetaria\",\n",
    "      \"canteen\",\n",
    "      \"Food\",\n",
    "      \"Cafetaria\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"Our university has canteen with variety of food available. Name of Canteen is Shamiyana \"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"menu\",\n",
    "   \"patterns\": [\n",
    "      \"food menu\",\n",
    "      \"food in canteen\",\n",
    "      \"Whats there on menu\",\n",
    "      \"what is available in college canteen\",\n",
    "      \"what foods can we get in college canteen\",\n",
    "      \"food variety\",\n",
    "      \"What is there to eat?\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"we serve Franky, Locho, Alu-puri, Kachori, Khavsa, Thaali and many more on menu\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"placement\",\n",
    "   \"patterns\": [\n",
    "      \"What is college placement\",\n",
    "      \"Which companies visit in college\",\n",
    "      \"What is average package\",\n",
    "      \"companies visit\",\n",
    "      \"package\",\n",
    "      \"About placement\",\n",
    "      \"placement\",\n",
    "      \"recruitment\",\n",
    "      \"companies\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"To know about placement at IIT Jodhpur visit https://spc.iitj.ac.in\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"ithod\",\n",
    "   \"patterns\": [\n",
    "      \"Who is HOD\",\n",
    "      \"Where is HOD\",\n",
    "      \"it hod\",\n",
    "      \"name of it hod\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"All engineering departments have only one hod Name Dr. Dip Sankar Banerjee who available in CSE Department\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"computerhod\",\n",
    "   \"patterns\": [\n",
    "      \"Who is computer HOD\",\n",
    "      \"Where is computer HOD\",\n",
    "      \"computer hod\",\n",
    "      \"name of computer hod\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"All engineering departments have only one hod Name Dr. Dip Sankar Banerjee who available in CSE Department \"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"extchod\",\n",
    "   \"patterns\": [\n",
    "      \"Who is extc HOD\",\n",
    "      \"Where is  extc HOD\",\n",
    "      \"extc hod\",\n",
    "      \"name of extc hod\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"Different school wise hod are different.So be more clear with your school or department\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"principal\",\n",
    "   \"patterns\": [\n",
    "      \"what is the name of principal\",\n",
    "      \"whatv is the principal name\",\n",
    "      \"principal name\",\n",
    "      \"Who is college principal\",\n",
    "      \"Where is principal's office\",\n",
    "      \"principal\",\n",
    "      \"name of principal\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"Dr. Dip Sankar Banerjee is  college principal and if you need any help then contact him directly.That is more appropriate\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"sem\",\n",
    "   \"patterns\": [\n",
    "      \"exam dates\",\n",
    "      \"exam schedule\",\n",
    "      \"When is semester exam\",\n",
    "      \"Semester exam timetable\",\n",
    "      \"sem\",\n",
    "      \"semester\",\n",
    "      \"exam\",\n",
    "      \"when is exam\",\n",
    "      \"exam timetable\",\n",
    "      \"exam dates\",\n",
    "      \"when is semester\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"Here is the Academic Calendar of IIT Jodhpur https://iitj.ac.in/academics/index.php?id=archives \"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"admission\",\n",
    "   \"patterns\": [\n",
    "      \"what is the process of admission\",\n",
    "      \"what is the admission process\",\n",
    "      \"How to take admission in your college\",\n",
    "      \"What is the process for admission\",\n",
    "      \"admission\",\n",
    "      \"admission process\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"Application can also be submitted online through the Unversity's  https://iitj.ac.in/admission/mtech.php?id=apply_online\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"scholarship\",\n",
    "   \"patterns\": [\n",
    "      \"scholarship\",\n",
    "      \"Is scholarship available\",\n",
    "      \"scholarship engineering\",\n",
    "      \"scholarship it\",\n",
    "      \"scholarship ce\",\n",
    "      \"scholarship mechanical\",\n",
    "      \"scholarship civil\",\n",
    "      \"scholarship chemical\",\n",
    "      \"scholarship for AI/ML\",\n",
    "      \"available scholarships\",\n",
    "      \"scholarship for computer engineering\",\n",
    "      \"scholarship for IT engineering\",\n",
    "      \"scholarship for mechanical engineering\",\n",
    "      \"scholarship for civil engineering\",\n",
    "      \"scholarship for chemical engineering\",\n",
    "      \"list of scholarship\",\n",
    "      \"comps scholarship\",\n",
    "      \"IT scholarship\",\n",
    "      \"mechanical scholarship\",\n",
    "      \"civil scholarship\",\n",
    "      \"chemical scholarship\",\n",
    "      \"automobile scholarship\",\n",
    "      \"first year scholarship\",\n",
    "      \"second year scholarship\",\n",
    "      \"third year scholarship\",\n",
    "      \"fourth year scholarship\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"Many government scholarships are supported by IIT Jodhpur. For details and updates visit https://iitj.ac.in/students/index.php?id=scholarships\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"facilities\",\n",
    "   \"patterns\": [\n",
    "      \"What facilities college provide\",\n",
    "      \"College facility\",\n",
    "      \"What are college facilities\",\n",
    "      \"facilities\",\n",
    "      \"facilities provided\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"IIT Jodhpur's Engineering department provides fully AC Lab with internet connection, smart classroom, Auditorium, library,canteen\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"college intake\",\n",
    "   \"patterns\": [\n",
    "      \"max number of students\",\n",
    "      \"number of seats per branch\",\n",
    "      \"number of seats in each branch\",\n",
    "      \"maximum number of seats\",\n",
    "      \"maximum students intake\",\n",
    "      \"What is college intake\",\n",
    "      \"how many stundent are taken in each branch\",\n",
    "      \"seat allotment\",\n",
    "      \"seats\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"For IT, Computer and extc 60 per branch and seat may be differ for different department.\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"uniform\",\n",
    "   \"patterns\": [\n",
    "      \"college dress code\",\n",
    "      \"college dresscode\",\n",
    "      \"what is the uniform\",\n",
    "      \"can we wear casuals\",\n",
    "      \"Does college have an uniform\",\n",
    "      \"Is there any uniform\",\n",
    "      \"uniform\",\n",
    "      \"what about uniform\",\n",
    "      \"do we have to wear uniform\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \" At IIT Jodhput Students are free to wear whatever they are comfortable in\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"committee\",\n",
    "   \"patterns\": [\n",
    "      \"what are the different committe in college\",\n",
    "      \"different committee in college\",\n",
    "      \"Are there any committee in college\",\n",
    "      \"Give me committee details\",\n",
    "      \"committee\",\n",
    "      \"how many committee are there in college\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"For the various committe in college contact this number: 7984864096\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"random\",\n",
    "   \"patterns\": [\n",
    "      \"I love you\",\n",
    "      \"Will you marry me\",\n",
    "      \"Do you love me\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"I am not program for this, please ask appropriate query\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"swear\",\n",
    "   \"patterns\": [\n",
    "      \"fuck\",\n",
    "      \"bitch\",\n",
    "      \"shut up\",\n",
    "      \"hell\",\n",
    "      \"stupid\",\n",
    "      \"idiot\",\n",
    "      \"dumb ass\",\n",
    "      \"asshole\",\n",
    "      \"fucker\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"please use appropriate language\",\n",
    "      \"Maintaining decency would be appreciated\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"vacation\",\n",
    "   \"patterns\": [\n",
    "      \"holidays\",\n",
    "      \"when will semester starts\",\n",
    "      \"when will semester end\",\n",
    "      \"when is the holidays\",\n",
    "      \"list of holidays\",\n",
    "      \"Holiday in these year\",\n",
    "      \"holiday list\",\n",
    "      \"about vacations\",\n",
    "      \"about holidays\",\n",
    "      \"When is vacation\",\n",
    "      \"When is holidays\",\n",
    "      \"how long will be the vacation\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"Academic calender is given to you by your class-soordinators after you join your respective classes\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"sports\",\n",
    "   \"patterns\": [\n",
    "      \"sports and games\",\n",
    "      \"give sports details\",\n",
    "      \"sports infrastructure\",\n",
    "      \"sports facilities\",\n",
    "      \"information about sports\",\n",
    "      \"Sports activities\",\n",
    "      \"please provide sports and games information\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"Our university encourages all-round development of students and hence provides sports facilities in the campus. For more details visit https://iitj.ac.in/students/index.php?id=facilities\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"salutaion\",\n",
    "   \"patterns\": [\n",
    "      \"okk\",\n",
    "      \"okie\",\n",
    "      \"nice work\",\n",
    "      \"well done\",\n",
    "      \"good job\",\n",
    "      \"thanks for the help\",\n",
    "      \"Thank You\",\n",
    "      \"its ok\",\n",
    "      \"Thanks\",\n",
    "      \"Good work\",\n",
    "      \"k\",\n",
    "      \"ok\",\n",
    "      \"okay\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"I am glad I helped you\",\n",
    "      \"welcome, anything else i can assist you with?\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"task\",\n",
    "   \"patterns\": [\n",
    "      \"what can you do\",\n",
    "      \"what are the thing you can do\",\n",
    "      \"things you can do\",\n",
    "      \"what can u do for me\",\n",
    "      \"how u can help me\",\n",
    "      \"why i should use you\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"I can answer to low-intermediate questions regarding college\",\n",
    "      \"You can ask me questions regarding college, and i will try to answer them\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"ragging\",\n",
    "   \"patterns\": [\n",
    "      \"ragging\",\n",
    "      \"is ragging practice active in college\",\n",
    "      \"does college have any antiragging facility\",\n",
    "      \"is there any ragging cases\",\n",
    "      \"is ragging done here\",\n",
    "      \"ragging against\",\n",
    "      \"antiragging facility\",\n",
    "      \"ragging juniors\",\n",
    "      \"ragging history\",\n",
    "      \"ragging incidents\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"We are Proud to tell you that IIT Jodhpur provides ragging free environment, and we have strict rules against ragging\"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "},\n",
    " {\n",
    "   \"tag\": \"hod\",\n",
    "   \"patterns\": [\n",
    "      \"hod\",\n",
    "      \"hod name\",\n",
    "      \"who is the hod\"\n",
    "   ],\n",
    "   \"responses\": [\n",
    "      \"HODs differ for each branch, please be more specific \"\n",
    "   ],\n",
    "   \"context_set\": \"\"\n",
    "}\n",
    "]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e38743a-6942-4add-b3b1-4e0f531295ec",
   "metadata": {},
   "source": [
    "## B) Build Model (train_chatbot.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0232124-11b9-4c42-b1d5-fcfeda4fa074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0859 - loss: 3.5263\n",
      "Epoch 2/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3076 - loss: 2.6257\n",
      "Epoch 3/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4626 - loss: 2.0231\n",
      "Epoch 4/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5908 - loss: 1.5456\n",
      "Epoch 5/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6295 - loss: 1.4541\n",
      "Epoch 6/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6785 - loss: 1.0256\n",
      "Epoch 7/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6875 - loss: 1.0720\n",
      "Epoch 8/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7777 - loss: 0.8443\n",
      "Epoch 9/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7097 - loss: 1.0591\n",
      "Epoch 10/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7322 - loss: 0.8453\n",
      "Epoch 11/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8231 - loss: 0.6116\n",
      "Epoch 12/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7507 - loss: 0.9013\n",
      "Epoch 13/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7461 - loss: 0.8736\n",
      "Epoch 14/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7859 - loss: 0.6537\n",
      "Epoch 15/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8081 - loss: 0.6465\n",
      "Epoch 16/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8315 - loss: 0.6171\n",
      "Epoch 17/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7748 - loss: 0.7954\n",
      "Epoch 18/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7878 - loss: 0.6883\n",
      "Epoch 19/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7915 - loss: 0.6978\n",
      "Epoch 20/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8341 - loss: 0.6852\n",
      "Epoch 21/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8271 - loss: 0.6336\n",
      "Epoch 22/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.5850\n",
      "Epoch 23/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8708 - loss: 0.4320\n",
      "Epoch 24/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8211 - loss: 0.6535\n",
      "Epoch 25/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8554 - loss: 0.6437\n",
      "Epoch 26/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8174 - loss: 0.5853\n",
      "Epoch 27/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8532 - loss: 0.5171\n",
      "Epoch 28/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8654 - loss: 0.4412\n",
      "Epoch 29/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8904 - loss: 0.5131\n",
      "Epoch 30/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8646 - loss: 0.4870\n",
      "Epoch 31/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 0.4569\n",
      "Epoch 32/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7992 - loss: 0.7595\n",
      "Epoch 33/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8672 - loss: 0.5441\n",
      "Epoch 34/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8152 - loss: 0.7991\n",
      "Epoch 35/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8579 - loss: 0.5238\n",
      "Epoch 36/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.9037\n",
      "Epoch 37/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8795 - loss: 0.4490\n",
      "Epoch 38/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8523 - loss: 0.6265\n",
      "Epoch 39/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8054 - loss: 0.8088\n",
      "Epoch 40/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8950 - loss: 0.4367\n",
      "Epoch 41/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.6195\n",
      "Epoch 42/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8465 - loss: 0.5590\n",
      "Epoch 43/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8482 - loss: 0.6724\n",
      "Epoch 44/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8249 - loss: 0.7110\n",
      "Epoch 45/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8327 - loss: 0.8018\n",
      "Epoch 46/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8878 - loss: 0.3805\n",
      "Epoch 47/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8463 - loss: 0.7897\n",
      "Epoch 48/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8444 - loss: 0.5580\n",
      "Epoch 49/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8270 - loss: 0.6957\n",
      "Epoch 50/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8519 - loss: 0.6439\n",
      "Epoch 51/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8741 - loss: 0.6100\n",
      "Epoch 52/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8497 - loss: 0.6457\n",
      "Epoch 53/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8591 - loss: 0.6850\n",
      "Epoch 54/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8782 - loss: 0.3533\n",
      "Epoch 55/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8406 - loss: 0.5670\n",
      "Epoch 56/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8502 - loss: 0.5362\n",
      "Epoch 57/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8395 - loss: 0.5716\n",
      "Epoch 58/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8951 - loss: 0.5046\n",
      "Epoch 59/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8718 - loss: 0.5059\n",
      "Epoch 60/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9157 - loss: 0.3827\n",
      "Epoch 61/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9012 - loss: 0.3693\n",
      "Epoch 62/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.3873\n",
      "Epoch 63/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8476 - loss: 0.7033\n",
      "Epoch 64/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8566 - loss: 0.5361\n",
      "Epoch 65/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8489 - loss: 0.6513\n",
      "Epoch 66/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8815 - loss: 0.4988\n",
      "Epoch 67/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8959 - loss: 0.3430\n",
      "Epoch 68/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8871 - loss: 0.4876\n",
      "Epoch 69/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8558 - loss: 0.5380\n",
      "Epoch 70/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8838 - loss: 0.5376\n",
      "Epoch 71/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8598 - loss: 0.8399\n",
      "Epoch 72/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8759 - loss: 0.4783\n",
      "Epoch 73/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8297 - loss: 0.7216\n",
      "Epoch 74/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8614 - loss: 0.5839\n",
      "Epoch 75/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8721 - loss: 0.6053\n",
      "Epoch 76/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8706 - loss: 0.6341\n",
      "Epoch 77/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8766 - loss: 0.4896\n",
      "Epoch 78/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.7947\n",
      "Epoch 79/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8969 - loss: 0.3647\n",
      "Epoch 80/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8764 - loss: 0.4721\n",
      "Epoch 81/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8826 - loss: 0.4970\n",
      "Epoch 82/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8798 - loss: 0.4294\n",
      "Epoch 83/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.4657\n",
      "Epoch 84/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.4897\n",
      "Epoch 85/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.5367\n",
      "Epoch 86/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8641 - loss: 0.7083\n",
      "Epoch 87/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.4860\n",
      "Epoch 88/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8214 - loss: 0.9498\n",
      "Epoch 89/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9006 - loss: 0.5271\n",
      "Epoch 90/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8814 - loss: 0.6242\n",
      "Epoch 91/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8626 - loss: 0.5852\n",
      "Epoch 92/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8849 - loss: 0.5122\n",
      "Epoch 93/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8655 - loss: 0.5405\n",
      "Epoch 94/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8779 - loss: 0.6034\n",
      "Epoch 95/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9009 - loss: 0.5350\n",
      "Epoch 96/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.4286\n",
      "Epoch 97/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.4327\n",
      "Epoch 98/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9058 - loss: 0.4280\n",
      "Epoch 99/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.6326\n",
      "Epoch 100/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8513 - loss: 0.6736\n",
      "Epoch 101/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8960 - loss: 0.3966\n",
      "Epoch 102/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8594 - loss: 0.6793\n",
      "Epoch 103/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.6119\n",
      "Epoch 104/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9059 - loss: 0.5181\n",
      "Epoch 105/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8708 - loss: 0.6855\n",
      "Epoch 106/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9028 - loss: 0.8638\n",
      "Epoch 107/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8514 - loss: 0.4584\n",
      "Epoch 108/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.5595\n",
      "Epoch 109/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8845 - loss: 0.5644\n",
      "Epoch 110/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.4485\n",
      "Epoch 111/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.4684\n",
      "Epoch 112/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8708 - loss: 0.4521\n",
      "Epoch 113/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9060 - loss: 0.3671\n",
      "Epoch 114/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.3933\n",
      "Epoch 115/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8597 - loss: 0.8271\n",
      "Epoch 116/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2958\n",
      "Epoch 117/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.6258\n",
      "Epoch 118/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8653 - loss: 0.5468\n",
      "Epoch 119/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.5370\n",
      "Epoch 120/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.3885\n",
      "Epoch 121/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.3356\n",
      "Epoch 122/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.3610\n",
      "Epoch 123/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.5126\n",
      "Epoch 124/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8918 - loss: 0.3235\n",
      "Epoch 125/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8674 - loss: 0.7292\n",
      "Epoch 126/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8957 - loss: 0.3811\n",
      "Epoch 127/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9105 - loss: 0.3801\n",
      "Epoch 128/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8898 - loss: 0.5885\n",
      "Epoch 129/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8785 - loss: 0.5473\n",
      "Epoch 130/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8694 - loss: 0.4381\n",
      "Epoch 131/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8692 - loss: 0.6232\n",
      "Epoch 132/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9010 - loss: 0.5874\n",
      "Epoch 133/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8728 - loss: 0.6969\n",
      "Epoch 134/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9067 - loss: 0.5831\n",
      "Epoch 135/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8649 - loss: 0.8708\n",
      "Epoch 136/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9204 - loss: 0.3454\n",
      "Epoch 137/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8670 - loss: 0.7026\n",
      "Epoch 138/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.4412\n",
      "Epoch 139/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8834 - loss: 0.5833\n",
      "Epoch 140/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.7028\n",
      "Epoch 141/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8816 - loss: 0.7174\n",
      "Epoch 142/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.4694\n",
      "Epoch 143/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.4263\n",
      "Epoch 144/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2662\n",
      "Epoch 145/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8855 - loss: 0.4691\n",
      "Epoch 146/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9373 - loss: 0.3197\n",
      "Epoch 147/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9041 - loss: 0.5841\n",
      "Epoch 148/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8842 - loss: 0.4472\n",
      "Epoch 149/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.7330\n",
      "Epoch 150/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8889 - loss: 0.5136\n",
      "Epoch 151/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8788 - loss: 0.6713\n",
      "Epoch 152/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.5109\n",
      "Epoch 153/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8762 - loss: 1.0423\n",
      "Epoch 154/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.3868\n",
      "Epoch 155/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.3229\n",
      "Epoch 156/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8940 - loss: 0.7763\n",
      "Epoch 157/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.5142\n",
      "Epoch 158/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9293 - loss: 0.3986\n",
      "Epoch 159/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8968 - loss: 0.6093\n",
      "Epoch 160/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.6984\n",
      "Epoch 161/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.4396\n",
      "Epoch 162/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9065 - loss: 0.4096\n",
      "Epoch 163/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9162 - loss: 0.3925\n",
      "Epoch 164/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8986 - loss: 0.4496\n",
      "Epoch 165/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9035 - loss: 0.5494\n",
      "Epoch 166/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8955 - loss: 0.4860\n",
      "Epoch 167/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.4831\n",
      "Epoch 168/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.4527\n",
      "Epoch 169/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.5709\n",
      "Epoch 170/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8950 - loss: 0.3796\n",
      "Epoch 171/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9210 - loss: 0.3765\n",
      "Epoch 172/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.4160\n",
      "Epoch 173/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9212 - loss: 0.3876\n",
      "Epoch 174/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8846 - loss: 0.5730\n",
      "Epoch 175/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9103 - loss: 0.5312\n",
      "Epoch 176/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.3387\n",
      "Epoch 177/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8978 - loss: 0.4548\n",
      "Epoch 178/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9217 - loss: 0.3154\n",
      "Epoch 179/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.4089\n",
      "Epoch 180/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.4346\n",
      "Epoch 181/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9106 - loss: 1.2990\n",
      "Epoch 182/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.4528\n",
      "Epoch 183/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.5429\n",
      "Epoch 184/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9174 - loss: 0.4553\n",
      "Epoch 185/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9043 - loss: 0.5437\n",
      "Epoch 186/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8899 - loss: 0.6039\n",
      "Epoch 187/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8879 - loss: 0.6006\n",
      "Epoch 188/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9377 - loss: 0.3305\n",
      "Epoch 189/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.3893\n",
      "Epoch 190/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.4724\n",
      "Epoch 191/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8906 - loss: 0.5374\n",
      "Epoch 192/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9010 - loss: 0.5615\n",
      "Epoch 193/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9421 - loss: 0.2267\n",
      "Epoch 194/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.5302\n",
      "Epoch 195/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9195 - loss: 0.4025\n",
      "Epoch 196/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9443 - loss: 0.2534\n",
      "Epoch 197/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8746 - loss: 0.7096\n",
      "Epoch 198/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9310 - loss: 0.3329\n",
      "Epoch 199/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8911 - loss: 0.3948\n",
      "Epoch 200/200\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9041 - loss: 0.4685\n",
      "Model trained and saved successfully in .keras format!\n"
     ]
    }
   ],
   "source": [
    "# train_chatbot.py\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load intents\n",
    "with open('intents.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Preparing data\n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "labels = []\n",
    "responses = {}\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        training_sentences.append(pattern)\n",
    "        training_labels.append(intent['tag'])\n",
    "    \n",
    "    responses[intent['tag']] = intent['responses']\n",
    "\n",
    "    if intent['tag'] not in labels:\n",
    "        labels.append(intent['tag'])\n",
    "\n",
    "# Encode labels\n",
    "lbl_encoder = LabelEncoder()\n",
    "lbl_encoder.fit(training_labels)\n",
    "training_labels = lbl_encoder.transform(training_labels)\n",
    "\n",
    "# Tokenize and lemmatize sentences\n",
    "def tokenize(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    return [lemmatizer.lemmatize(w.lower()) for w in tokens]\n",
    "\n",
    "all_words = []\n",
    "for sentence in training_sentences:\n",
    "    all_words.extend(tokenize(sentence))\n",
    "\n",
    "all_words = sorted(set(all_words))\n",
    "\n",
    "X_train = []\n",
    "for sentence in training_sentences:\n",
    "    bag = []\n",
    "    words = tokenize(sentence)\n",
    "    for w in all_words:\n",
    "        bag.append(1) if w in words else bag.append(0)\n",
    "    X_train.append(bag)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(training_labels)\n",
    "\n",
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(X_train[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(labels), activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=8, verbose=1)\n",
    "\n",
    "# Save model in new Keras format\n",
    "model.save('chatbot_model.keras')\n",
    "\n",
    "# Save other files\n",
    "pickle.dump(all_words, open('words.pkl', 'wb'))\n",
    "pickle.dump(lbl_encoder, open('labels.pkl', 'wb'))\n",
    "\n",
    "print(\"Model trained and saved successfully in .keras format!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e32ff86-d9bf-4d3b-89e5-811a03084780",
   "metadata": {},
   "source": [
    "## C) Chatbot Core Logic (chatbot.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68bb90fc-0e60-438b-ac91-8272dd9b4b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('chatbot_model.keras')  # Make sure to load the correct model format\n",
    "# Load the other assets (words and labels)\n",
    "with open('words.pkl', 'rb') as f:\n",
    "    all_words = pickle.load(f)\n",
    "\n",
    "with open('labels.pkl', 'rb') as f:\n",
    "    lbl_encoder = pickle.load(f)\n",
    "\n",
    "# Load intents\n",
    "with open('intents.json') as file:\n",
    "    intents = json.load(file)\n",
    "\n",
    "# Function to clean and process text input\n",
    "def clean_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word.lower()) for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "# Function to create a bag of words for prediction\n",
    "def bag_of_words(text):\n",
    "    tokens = clean_text(text)\n",
    "    bag = [0] * len(all_words)\n",
    "    for s in tokens:\n",
    "        for i, word in enumerate(all_words):\n",
    "            if word == s:\n",
    "                bag[i] = 1\n",
    "    return np.array(bag)\n",
    "\n",
    "# Predict the intent of the user's input\n",
    "def predict_intent(text):\n",
    "    bow = bag_of_words(text)  # Create bag of words\n",
    "    prediction = model.predict(np.array([bow]))  # Predict using the model\n",
    "    intent_index = np.argmax(prediction)  # Get the index of the highest probability\n",
    "    confidence = prediction[0][intent_index]  # Get the confidence of the prediction\n",
    "    intent = lbl_encoder.inverse_transform([intent_index])[0]  # Map index to intent tag\n",
    "    return intent, confidence\n",
    "\n",
    "# Get a response based on the predicted intent\n",
    "def get_response(intent_tag):\n",
    "    for intent in intents['intents']:\n",
    "        if intent['tag'] == intent_tag:\n",
    "            return random.choice(intent['responses'])\n",
    "    return \"I am not sure how to answer that.\"\n",
    "\n",
    "# Main function to get the chatbot's response\n",
    "def chatbot_response(user_input):\n",
    "    intent, confidence = predict_intent(user_input)\n",
    "    if confidence > 0.6:\n",
    "        return get_response(intent)\n",
    "    else:\n",
    "        return get_response(\"noanswer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c35c44-4506-40bf-85b7-85d60e85ec34",
   "metadata": {},
   "source": [
    "## D) GUI Integration (gui.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "123b646c-572c-44c1-9cdc-7fa24af2e4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import Scrollbar, Text, Entry, Button, END\n",
    "from tensorflow.keras.models import load_model\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load Files\n",
    "model = load_model('chatbot_model.keras')  # Correct model file\n",
    "intents = json.loads(open('intents.json', encoding='utf-8').read())\n",
    "words = pickle.load(open('words.pkl', 'rb'))\n",
    "labels = pickle.load(open('labels.pkl', 'rb'))\n",
    "\n",
    "def tokenize(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    return [lemmatizer.lemmatize(word.lower()) for word in tokens]\n",
    "\n",
    "def bag_of_words(sentence):\n",
    "    tokens = tokenize(sentence)\n",
    "    bag = [0] * len(words)\n",
    "    for s in tokens:\n",
    "        for i, word in enumerate(words):\n",
    "            if word == s:\n",
    "                bag[i] = 1\n",
    "    return np.array(bag)\n",
    "\n",
    "def chatbot_response(text):\n",
    "    bow = bag_of_words(text)\n",
    "    res = model.predict(np.array([bow]))[0]\n",
    "    threshold = 0.4  # Lowered the threshold for more varied responses\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > threshold]\n",
    "\n",
    "    if results:\n",
    "        results.sort(key=lambda x: x[1], reverse=True)\n",
    "        tag = labels.inverse_transform([results[0][0]])[0]  # Fixed this line\n",
    "\n",
    "        for intent in intents['intents']:\n",
    "            if intent['tag'] == tag:\n",
    "                return random.choice(intent['responses'])\n",
    "\n",
    "    return \"I didn't get that. Can you rephrase?\"\n",
    "\n",
    "# GUI Setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Hem's AI Chatbot for IIT Jodhpur Enquires\")\n",
    "root.geometry(\"500x600\")\n",
    "root.configure(bg=\"#17202A\")\n",
    "\n",
    "# Chat window\n",
    "chat_log = Text(root, bd=1, bg=\"#2C3E50\", fg=\"#EAECEE\", font=(\"Helvetica\", 14), wrap='word')\n",
    "chat_log.pack(padx=10, pady=10, fill=tk.BOTH, expand=True)\n",
    "\n",
    "scrollbar = Scrollbar(chat_log)\n",
    "scrollbar.place(relheight=1, relx=0.974)\n",
    "scrollbar.config(command=chat_log.yview)\n",
    "chat_log['yscrollcommand'] = scrollbar.set\n",
    "chat_log.config(state=tk.DISABLED)\n",
    "\n",
    "# Entry box\n",
    "entry_frame = tk.Frame(root, bg=\"#17202A\")\n",
    "entry_frame.pack(padx=10, pady=10, fill=tk.X)\n",
    "\n",
    "entry_box = Entry(entry_frame, bd=1, bg=\"#2C3E50\", fg=\"#EAECEE\", font=(\"Helvetica\", 14))\n",
    "entry_box.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 10))\n",
    "\n",
    "def send_message(event=None):\n",
    "    msg = entry_box.get().strip()\n",
    "    if msg == \"\":\n",
    "        return\n",
    "\n",
    "    chat_log.config(state=tk.NORMAL)\n",
    "    chat_log.insert(END, \"You: \" + msg + \"\\n\\n\")\n",
    "    entry_box.delete(0, END)\n",
    "\n",
    "    res = chatbot_response(msg)\n",
    "    chat_log.insert(END, \"Bot: \" + res + \"\\n\\n\")\n",
    "\n",
    "    chat_log.config(state=tk.DISABLED)\n",
    "    chat_log.yview(END)\n",
    "\n",
    "send_button = Button(entry_frame, text=\"Send\", font=(\"Helvetica\", 13, \"bold\"), bg=\"#ABB2B9\", command=send_message)\n",
    "send_button.pack(side=tk.RIGHT)\n",
    "\n",
    "# Bind Enter key to send message\n",
    "root.bind('<Return>', send_message)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225985c5-4491-4b5f-9712-5877e8b751fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
